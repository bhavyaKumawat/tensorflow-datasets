{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST kaggle.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bhavyaKumawat/tensorflow-datasets/blob/main/MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-uNHzs-w3OEU"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CvowrqyTp0o"
      },
      "source": [
        "import zipfile\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jqQe5p6x4oW0"
      },
      "source": [
        "## Download Kaggle Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NylzcKRX3x1G"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnSHW9PXbJX_"
      },
      "source": [
        "! mkdir /root/.kaggle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IkGGaQcf3LEa"
      },
      "source": [
        "! cp 'drive/MyDrive/Colab Notebooks/kaggle.json' '/root/.kaggle/kaggle.json'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQELyAkF3x3t"
      },
      "source": [
        "! kaggle competitions download -c digit-recognizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INHX-Vfj3x6I"
      },
      "source": [
        "files = ['train.csv.zip', 'test.csv.zip']\n",
        "\n",
        "for File in files:\n",
        "  with zipfile.ZipFile(File, 'r') as zip_ref:\n",
        "      zip_ref.extractall(os.getcwd())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ym_spwE03x8x"
      },
      "source": [
        "train = pd.read_csv(\"train.csv\")\n",
        "test = pd.read_csv(\"test.csv\")\n",
        "print(\"train shape: \", train.shape)\n",
        "print(\"test shape: \", test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jsuv9NCb69-Y"
      },
      "source": [
        "type(train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBLQVo2U6-Bf"
      },
      "source": [
        "x_train1 , y_train1 = train.drop('label', axis = 1), train['label']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IhMqhD_k60ec"
      },
      "source": [
        "x_train1 = x_train1.values.reshape(-1, 28, 28)\n",
        "y_train1 = y_train1.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8Jh-CUf9Qo7"
      },
      "source": [
        "print(\"x_train1 shape: \", x_train1.shape)\n",
        "print(\"y_train1 shape: \", y_train1.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJ4sh6lEa-o1"
      },
      "source": [
        "## Download keras Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U34DUtJRU_zq"
      },
      "source": [
        "(x_train2, y_train2), (x_test, y_test) = keras.datasets.mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Swos9DsPV2Ez"
      },
      "source": [
        "print(\"x_train2 shape: \", x_train2.shape)\n",
        "print(\"y_train2 shape: \", y_train2.shape)\n",
        "print(\"x_test shape: \", x_test.shape)\n",
        "print(\"y_test shape: \", y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpyDIkiEWmCZ"
      },
      "source": [
        "type(x_train2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7o8AJhq_e3g"
      },
      "source": [
        "## Concatenate both the datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BP8nuKtN-l0M"
      },
      "source": [
        "x_train = np.concatenate((x_train2, x_train1))\n",
        "y_train = np.concatenate((y_train2, y_train1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GO0pGZPn_iBJ"
      },
      "source": [
        "print(\"x_train shape: \", x_train.shape)\n",
        "print(\"y_train shape: \", y_train.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwwq-E2xlgok"
      },
      "source": [
        "## Plot some images in dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h98DzPdQkJlr"
      },
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(x_train[i], cmap=plt.cm.binary)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Dy-k59Gb6TM"
      },
      "source": [
        "Scale images to the [0, 1] range"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lg-Et3xRXR5z"
      },
      "source": [
        "x_train = x_train /255.0\n",
        "x_test = x_test /255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBCKIqaWcs5d"
      },
      "source": [
        "Reshape images to (28, 28, 1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-ey5DsMYBuP"
      },
      "source": [
        "x_train = np.expand_dims(x_train, -1)\n",
        "x_test = np.expand_dims(x_test, -1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XeaqzVcpcrhp"
      },
      "source": [
        "print(\"x_train new shape: \", x_train.shape)\n",
        "print(\"x_test new shape: \", x_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6f_cQ6Tt6b3"
      },
      "source": [
        "## Data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cpuqMuTt6si"
      },
      "source": [
        "validation_split = 0.1\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range = 30,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    zoom_range = 0.2,\n",
        "    fill_mode = 'nearest',\n",
        "    validation_split = validation_split,\n",
        "\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTj2RbFSt602"
      },
      "source": [
        "train_generator = datagen.flow(x_train, \n",
        "                               y_train, \n",
        "                               batch_size = 32,\n",
        "                               subset='training'\n",
        ")\n",
        "\n",
        "valid_generator = datagen.flow(x_train,\n",
        "                              y_train,\n",
        "                              batch_size= 8, \n",
        "                              subset='validation'\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anQZ4rrEgZAO"
      },
      "source": [
        "## Build the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfwomCDaWHvW"
      },
      "source": [
        "[How to choose CNN Architecture MNIST](https://www.kaggle.com/cdeotte/how-to-choose-cnn-architecture-mnist)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lfBDwMLe_H0"
      },
      "source": [
        "model = keras.Sequential([\n",
        "                          keras.layers.Conv2D(32, (3, 3), activation= 'relu', input_shape = (28, 28 ,1)),\n",
        "                          keras.layers.BatchNormalization(),\n",
        "                          keras.layers.Conv2D(32, (3, 3), activation= 'relu', input_shape = (28, 28 ,1)),\n",
        "                          keras.layers.BatchNormalization(),\n",
        "                          keras.layers.MaxPooling2D((2, 2)),\n",
        "                          keras.layers.Dropout(0.4),\n",
        "\n",
        "                          keras.layers.Conv2D(64, (3, 3), activation= 'relu'),\n",
        "                          keras.layers.BatchNormalization(),\n",
        "                          keras.layers.Conv2D(64, (3, 3), activation= 'relu'),\n",
        "                          keras.layers.BatchNormalization(),\n",
        "                          keras.layers.MaxPooling2D((2, 2)),\n",
        "                          keras.layers.Dropout(0.4),\n",
        "\n",
        "                          keras.layers.Flatten(),\n",
        "                          keras.layers.Dense(256, activation= 'relu'),\n",
        "                          keras.layers.BatchNormalization(),\n",
        "                          keras.layers.Dropout(0.4),\n",
        "                          keras.layers.Dense(10, activation = 'softmax')                          \n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-XkqB_ql0mm"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2E7XDo-vmHAA"
      },
      "source": [
        "optimizer = Adam(learning_rate = 1e-03) \n",
        "model.compile(optimizer = optimizer, loss = 'sparse_categorical_crossentropy', metrics= 'accuracy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkjNv-BdWfGw"
      },
      "source": [
        "## CallBacks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sgw8vbUNSOSv"
      },
      "source": [
        "earlyStopping = keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YiF-eHX7nAO_"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RpozjJzKmh-E"
      },
      "source": [
        "history = model.fit(train_generator, \n",
        "                    steps_per_epoch= (len(x_train)*(1-validation_split)) / 32,                    \n",
        "                    epochs= 30, \n",
        "                    validation_data= valid_generator,\n",
        "                    validation_steps= (len(x_train)* validation_split) / 8,\n",
        "                    callbacks = [earlyStopping]\n",
        "                    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ryn3SEYrY4IN"
      },
      "source": [
        "## Visualizations of the image as it passes through the convolutions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJENf82WYydJ"
      },
      "source": [
        "# Let's define a new Model that will take an image as input, and will output\n",
        "# intermediate representations for all layers in the previous model \n",
        "feature_extractor = keras.models.Model(    \n",
        "    inputs = model.input, \n",
        "    outputs = [layer.output for layer in model.layers]\n",
        "    )\n",
        "# an input image from the training set.\n",
        "img = x_train[2052]\n",
        "\n",
        "# Add the image to a batch\n",
        "x = np.expand_dims(img, axis = 0)  \n",
        "\n",
        "# Let's run our image through our network, thus obtaining all\n",
        "# intermediate representations for this image.\n",
        "successive_feature_maps = feature_extractor.predict(x)\n",
        "\n",
        "# These are the names of the layers, so can have them as part of our plot\n",
        "layer_names = [layer.name for layer in model.layers]\n",
        "\n",
        "# Now let's display our representations\n",
        "for layer_name, feature_map in zip(layer_names, successive_feature_maps):\n",
        "    # Just do this for the conv / maxpool layers, not the fully-connected layers\n",
        "    if len(feature_map.shape) == 4:\n",
        "        #The feature map has shape (1, size, size, n_features)\n",
        "        n_features = feature_map.shape[-1]  \n",
        "        size = feature_map.shape[1]\n",
        "        # We will tile our images in this matrix\n",
        "        display_grid = np.zeros((size, size * n_features))\n",
        "        for i in range(n_features):\n",
        "            # Postprocess the feature to make it visually palatable\n",
        "            x = feature_map[0, :, :, i]\n",
        "            x -= x.mean()\n",
        "            x /= x.std()\n",
        "            x *= 64\n",
        "            x += 128\n",
        "            x = np.clip(x, 0, 255).astype('uint8')\n",
        "            # We'll tile each filter into this big horizontal grid\n",
        "            display_grid[:, i * size : (i + 1) * size] = x\n",
        "        # Display the grid\n",
        "        scale = 20. / n_features\n",
        "        plt.figure(figsize=(scale * n_features, scale))\n",
        "        plt.title(layer_name)\n",
        "        plt.grid(False)\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "        plt.imshow(display_grid, aspect='auto', cmap='viridis')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Lw9pARimEFQ"
      },
      "source": [
        "## Wrong Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlr5DsL8mDey"
      },
      "source": [
        "predictions = model.predict(x_train)\n",
        "predicted_classes = np.argmax(predictions,axis=1)\n",
        "wrong_predictions = x_train[predicted_classes != y_train]\n",
        "indices = np.nonzero((predicted_classes != y_train))[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skqCPHTxopy4"
      },
      "source": [
        "number = wrong_predictions.shape[0]\n",
        "print(\"Number of wrong predictions : \", number ) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixonTLYBpBnO"
      },
      "source": [
        "plt.figure(figsize=(10, 15))\n",
        "for i in range(100):\n",
        "    plt.subplot(10 ,10,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.title(indices[i])\n",
        "    plt.imshow(wrong_predictions[i].reshape(28, 28), cmap=plt.cm.binary)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewsfn_LwfE5M"
      },
      "source": [
        "## Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_JYWEQdfN4f"
      },
      "source": [
        "def plot_confusion_matrix(cm, classes):\n",
        "    \n",
        "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "    plt.title('Confusion matrix')\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "        \n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ybj9EfifN7a"
      },
      "source": [
        "confusion_mtx = confusion_matrix(y_train, predicted_classes)\n",
        "plot_confusion_matrix(confusion_mtx, classes = range(10))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgNt6ZP4vJ1t"
      },
      "source": [
        "## Training vs Validation accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4ZGajFFnK5v"
      },
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LkwuskcnurfP"
      },
      "source": [
        "model.evaluate(x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0Qt_Hqct1jN"
      },
      "source": [
        "## Submission"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sd8gii0Vt0w6"
      },
      "source": [
        "test = test.values.reshape(-1, 28, 28, 1)\n",
        "test = test / 255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvxZ7jmxt5pc"
      },
      "source": [
        "predictions = np.argmax( model.predict(test) ,axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vz3u85jbt75Z"
      },
      "source": [
        "data = {'ImageId': pd.Series(range(1 , len(predictions)+1)), \n",
        "        'Label':predictions} \n",
        "\n",
        "submission = pd.DataFrame(data) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGRjGpavt_Pr"
      },
      "source": [
        "submission.to_csv('submission.csv'  , index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6UYmSF12uBCH"
      },
      "source": [
        "! kaggle competitions submit -c digit-recognizer -f submission.csv -m 'accuracy 99.5%'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQpKbTkuiQnj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}